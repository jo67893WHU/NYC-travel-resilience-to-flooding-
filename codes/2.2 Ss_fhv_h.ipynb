{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1ee69-fffe-41a0-9481-a704ddb3f868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport Seasonal_Outliers\n",
    "import importlib\n",
    "\n",
    "importlib.reload(Seasonal_Outliers)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from numba import jit,cuda\n",
    "\n",
    "import Ipynb_importer\n",
    "# import Data_Cleaning_Taxi\n",
    "from prophet import Prophet\n",
    "import logging\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "import gc\n",
    "\n",
    "def read(file):\n",
    "    print(file)\n",
    "    df = pd.read_parquet(file)\n",
    "    print(df.head())\n",
    "    car_type=''\n",
    "    if 'fhv_' in file:\n",
    "        car_type='fhv'\n",
    "        df.rename(columns={'dropOff_datetime':'dropoff_datetime',\n",
    "                          'PUlocationID':'PULocationID',\n",
    "                          'DOlocationID':'DOLocationID'},inplace=True)\n",
    "        \n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')\n",
    "    df['pickup_date'] = df['pickup_datetime'].dt.date\n",
    "    df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'], errors='coerce')\n",
    "    df['dropoff_date'] = df['dropoff_datetime'].dt.date\n",
    "    df['Day of week'] = df['pickup_datetime'].dt.dayofweek\n",
    "    dt_wkends = df[df['Day of week']>4]['pickup_date'].unique()\n",
    "    \n",
    "    \n",
    "    if car_type=='fhv':\n",
    "        \n",
    "        df['pickup_datetime'] = df['pickup_datetime'].dt.round(freq='1h').dt.ceil(freq='2h').dt.floor(freq='4h')\n",
    "        df['dropoff_datetime'] = df['dropoff_datetime'].dt.round(freq='1h').dt.ceil(freq='2h').dt.floor(freq='4h')\n",
    "        return df,dt_wkends.tolist()\n",
    "    \n",
    "    df.drop(['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num','shared_request_flag',\n",
    "             'shared_match_flag', 'access_a_ride_flag', 'wav_request_flag', 'wav_match_flag'], axis=1,inplace=True)\n",
    "    \n",
    "    df['trip_time'] = pd.to_timedelta(df['trip_time'],unit='S')/pd.Timedelta(1,'h')\n",
    "    df['request_datetime'] = pd.to_datetime(df['request_datetime'], errors='coerce')\n",
    "    df['on_scene_datetime'] = pd.to_datetime(df['on_scene_datetime'], errors='coerce')\n",
    "    \n",
    "\n",
    "    df['pickup_datetime'] = df['pickup_datetime'].dt.round(freq='1h').dt.ceil(freq='2h').dt.floor(freq='4h')\n",
    "    df['dropoff_datetime'] = df['dropoff_datetime'].dt.round(freq='1h').dt.ceil(freq='2h').dt.floor(freq='4h')\n",
    "\n",
    "    return df,dt_wkends.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def combine_df(idir,files):\n",
    "    df = pd.DataFrame()\n",
    "    dt_non_work = []#non-working day\n",
    "    for fi in files:\n",
    "        dfi,dt_wkends = read(idir+fi)\n",
    "        df = df.append(dfi,ignore_index=True)\n",
    "        del dfi\n",
    "        gc.collect()\n",
    "        dt_non_work+=dt_wkends\n",
    "    holiday = pd.to_datetime(pd.Series(['2021-07-04','2021-07-05','2021-09-06','2021-09-16','2021-10-11'])).dt.date.unique()\n",
    "    dt_non_work = np.append(dt_non_work,holiday)#Labor Day\n",
    "\n",
    "    return df,dt_non_work\n",
    "\n",
    "\n",
    "def vis(idir,outliers,col,title):\n",
    "    \n",
    "    start = pd.to_datetime('07/01/2021 00:00:00')\n",
    "    end = pd.to_datetime('10/31/2021 23:59:59')\n",
    "    dt_range = pd.to_datetime(pd.date_range(start=start, end=end,freq='4H'))\n",
    "    df = pd.DataFrame(index=outliers[col[0]].unique(),columns=dt_range)\n",
    "    df = df.fillna(0).astype('float')\n",
    "    for idx in df.index:#datetime\n",
    "        vals = outliers[outliers[col[0]]==idx][[col[1]]].values\n",
    "        for val in vals:\n",
    "            if val in dt_range.values:\n",
    "                df.loc[idx][val] = outliers.loc[(outliers[col[0]]==idx)&(outliers[col[1]]==val[0])]['norm_resid']\n",
    "\n",
    "    figsize=(60, 20)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # my_colors=['whitesmoke','orangered']\n",
    "    \n",
    "    ax = sns.heatmap(df, cmap='bwr', center=0, xticklabels = df.columns.strftime('%Y-%m-%d,%H'),\n",
    "                     cbar_kws={\"shrink\":0.5},zorder=1)#square=True,\n",
    "\n",
    "    for i in range(df.shape[0]+1):\n",
    "        ax.axhline(i, color='white', lw=1.5,zorder=2)\n",
    "    y1 = 0\n",
    "    y2 = len(df)\n",
    "\n",
    "    # ida_window = pd.to_datetime(['2021-08-26 00','2021-09-04 00'])\n",
    "    # ida_nyc_window = pd.to_datetime(['2021-09-01 00','2021-09-02 00'])\n",
    "    xlabels = ax.get_xticklabels()\n",
    "    print(xlabels[0].get_text())\n",
    "    print(xlabels[0])\n",
    "\n",
    "    xs = [ x.get_position()[0] for x in xlabels if str(x.get_text()) in [\"2021-09-01,00\",\"2021-09-03,00\"]]\n",
    "    x1 = xs[0]-0.5\n",
    "    x2 = xs[1]+0.5\n",
    "    print(xs)\n",
    "    # ax.fill_between([x1,x2],ida_window[0],ida_window[1], color='lightskyblue', alpha=0.4)\n",
    "    ax.fill_between([x1,x2],y1,y2,alpha=0.5, color='none',edgecolor='blue', zorder=3, label='Ida',linewidth=3)\n",
    "    \n",
    "    xs2 = [ x.get_position()[0] for x in xlabels if str(x.get_text()) in [\"2021-08-21,00\",\"2021-08-24,00\"]]\n",
    "    x12 = xs2[0]-0.5\n",
    "    x22 = xs2[1]+0.5\n",
    "    print(xs2)\n",
    "    ax.fill_between([x12,x22],y1,y2,alpha=0.8, color='none',edgecolor='gold', zorder=3,label='Henri',linewidth=3)\n",
    "    \n",
    "    xs3 = [ x.get_position()[0] for x in xlabels if str(x.get_text()) in [\"2021-07-08,00\",\"2021-07-10,00\"]]\n",
    "    x13 = xs3[0]-0.5\n",
    "    x23 = xs3[1]+0.5\n",
    "    print(xs3)\n",
    "    ax.fill_between([x13,x23],y1,y2, alpha=0.5, color='none',edgecolor='green', zorder=3, label='Elsa',linewidth=3)\n",
    "    \n",
    "    xs4 = [ x.get_position()[0] for x in xlabels if str(x.get_text()) in [\"2021-10-25,00\",\"2021-10-27,00\"]]\n",
    "    x14 = xs4[0]-0.5\n",
    "    x24 = xs4[1]+0.5\n",
    "    print(xs4)\n",
    "    ax.fill_between([x14,x24],y1,y2, alpha=0.5, color='none',edgecolor='deeppink', zorder=3,label=\"Nor'eastern\",linewidth=3)\n",
    "    \n",
    "\n",
    "    for i, label in enumerate(xlabels):\n",
    "        if i % 2 == 0:\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "    if \"Line's\" in title:\n",
    "        ax.tick_params(axis='x', labelsize=7)    \n",
    "    # ax.set_title(title)\n",
    "    ax.legend(ncol=4, loc='upper right',fontsize=40)\n",
    "    # \n",
    "    fig = plt.gcf()\n",
    "    cax = fig.axes[-1]\n",
    "    plt.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.9, wspace=0.2, hspace=0.2)\n",
    "    cax.set_position([.796, .2, .03, .6]) # \n",
    "    plt.savefig(idir+'result/'+title.replace(':','_').replace('/',' ')+'.png',format='png',bbox_inches='tight',dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "@jit(target_backend='cuda')     \n",
    "def find_outliers(idir,df,title):\n",
    "    if \"Pickups\" in title:\n",
    "        col = [\"PULocationID\",'pickup_datetime']\n",
    "    elif \"Dropoffs\" in title:\n",
    "        col = [\"DOLocationID\",'dropoff_datetime']\n",
    "    gps = df.groupby([col[0]])\n",
    "    # names = df[col[0]].unique()\n",
    "    outs = pd.DataFrame()\n",
    "    stas = pd.DataFrame()\n",
    "    for nm,df2 in gps:\n",
    "        # if len(df2)<200:\n",
    "        #     continue\n",
    "        nm = 'Z'+ str(nm)\n",
    "        df2['index'] = df2.index\n",
    "        sta_df = pd.DataFrame()\n",
    "        sta_df['cnt'] = df2.groupby([col[1]]).count()['index']\n",
    "        key='cnt'\n",
    "        if ' FHV' in title:\n",
    "            if (sta_df['cnt'].mean()<6):\n",
    "                continue\n",
    "        elif 'HVFHV' in title:\n",
    "            if (sta_df['cnt'].mean()<12):\n",
    "                continue\n",
    "        elif (sta_df['cnt'].mean()<12):\n",
    "            continue\n",
    "        out = pd.DataFrame()\n",
    "        tmp,forecast = Seasonal_Outliers.seasonal_de_hour(sta_df,key,plot=False)\n",
    "        if len(tmp)>0:\n",
    "            out[col[1]] = tmp\n",
    "            out[col[0]] = nm\n",
    "            outs = pd.concat([outs,out[col]],ignore_index=True)\n",
    "            forecast[col] = nm\n",
    "            stas = pd.concat([stas,forecast],ignore_index=True)\n",
    "\n",
    "    sst = stas[['ds','norm_resid',col[0]]]\n",
    "    print(sst,outs)\n",
    "    sst['ds'] = pd.to_datetime(sst['ds'], errors='coerce')\n",
    "    sst[col[1]] = sst['ds']\n",
    "    outs = pd.merge(outs,sst,on=col)\n",
    "    print(outs)\n",
    "    \n",
    "    vis(idir,outs,col, title)\n",
    "    stas.to_csv(idir+'result/'+title.replace(':','_').replace('/',' ')+'.csv',index=False)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def run(idir,files,_title):\n",
    "        \n",
    "    keys_dict = {\n",
    "        \"Zone's pickups\":[''],\n",
    "        \"Zone's dropoffs\":[''],\n",
    "                 \n",
    "                }\n",
    "    # df,dt_non_work = combine_df(idir,files)\n",
    "\n",
    "\n",
    "    for k,v in keys_dict.items():\n",
    "        if \"pickups\" in k:\n",
    "            title = _title + \"Zone's Pickups\"\n",
    "        if \"dropoffs\" in k:\n",
    "            title = _title + \"Zone's Dropoffs\"\n",
    "        find_outliers(idir,df,title)\n",
    "        \n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    input_dir = \"\"\n",
    "    items = [i for i in os.listdir(input_dir) if os.path.splitext(i)[1] == '.parquet']\n",
    "    f_fi = [i for i in items if 'fhv_' in i]\n",
    "    hf_fi = [i for i in items if 'fhvhv' in i]\n",
    "    \n",
    "    _f_title = 'Hourly Stationarity of FHV Taxi: '\n",
    "    _hf_title = 'Hourly Stationarity of HVFHV Taxi: '\n",
    "    \n",
    "    df_f,dt_non_work = combine_df(input_dir,f_fi)\n",
    "    df_hf,dt_non_work = combine_df(input_dir,hf_fi)\n",
    "    \n",
    "    df = pd.concat([df_f,df_hf],ignore_index=True)\n",
    "    # print(df)\n",
    "    \n",
    "    del df_f\n",
    "    del df_hf\n",
    "    gc.collect()\n",
    "   \n",
    "    _title = 'Hourly Stationarity of HVFHV Taxi '\n",
    "    run(input_dir, df, _title)\n",
    "\n",
    "    # run(input_dir, f_fi, _f_title)\n",
    "    # run(input_dir, hf_fi, _hf_title)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974751a3-6e2b-4e18-bddf-b643b6456014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
