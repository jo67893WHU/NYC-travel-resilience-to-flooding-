{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c1ee69-fffe-41a0-9481-a704ddb3f868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport Seasonal_Outliers\n",
    "import importlib\n",
    "importlib.reload(Seasonal_Outliers)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import Ipynb_importer\n",
    "from numba import jit,cuda\n",
    "\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "def read(file):\n",
    "    print(file)\n",
    "    df = pd.read_parquet(file)\n",
    "    \n",
    "    # print(df.head())\n",
    "\n",
    "    if 'green' in file:\n",
    "        prefix='lpep_'\n",
    "    elif 'yellow' in file:\n",
    "        prefix='tpep_'\n",
    "        \n",
    "    df[prefix+'pickup_datetime'] = pd.to_datetime(df[prefix+'pickup_datetime'], errors='coerce')\n",
    "    df['pickup_date'] = df[prefix+'pickup_datetime'].dt.date\n",
    "    df[prefix+'dropoff_datetime'] = pd.to_datetime(df[prefix+'dropoff_datetime'], errors='coerce')\n",
    "    df['dropoff_date'] = df[prefix+'dropoff_datetime'].dt.date\n",
    "    \n",
    "    \n",
    "    df.rename(columns = {prefix+'pickup_datetime':'pickup_datetime'}, inplace = True)\n",
    "    df.rename(columns = {prefix+'dropoff_datetime':'dropoff_datetime'}, inplace = True)\n",
    "    \n",
    "    df['pickup_datetime'] = df['pickup_datetime'].dt.round(freq='1h').dt.ceil(freq='2h').dt.floor(freq='4h')\n",
    "    df['dropoff_datetime'] = df['dropoff_datetime'].dt.round(freq='1h').dt.ceil(freq='2h').dt.floor(freq='4h')\n",
    "    \n",
    "    df['Day of week'] = df['pickup_datetime'].dt.dayofweek\n",
    "    dt_wkends = df[df['Day of week']>4]['pickup_date'].unique()\n",
    "    \n",
    "    return df,dt_wkends.tolist()\n",
    "\n",
    "\n",
    "def combine_df(idir,files):\n",
    "    df = pd.DataFrame()\n",
    "    dt_non_work = []#non-working day\n",
    "    for fi in files:\n",
    "        dfi,dt_wkends = read(idir+fi)\n",
    "        df = df.append(dfi,ignore_index=True)\n",
    "        dt_non_work+=dt_wkends\n",
    "    holiday = pd.to_datetime(pd.Series(['2021-07-04','2021-07-05','2021-09-06','2021-09-16','2021-10-11'])).dt.date.unique()\n",
    "    dt_non_work = np.append(dt_non_work,holiday)#Labor Day\n",
    "\n",
    "    return df,dt_non_work\n",
    "\n",
    "\n",
    "def vis(idir,outliers,col,title):\n",
    "    \n",
    "    start = pd.to_datetime('07/01/2021 00:00:00')\n",
    "    end = pd.to_datetime('10/31/2021 23:59:59')\n",
    "    dt_range = pd.to_datetime(pd.date_range(start=start, end=end,freq='4H'))\n",
    "    df = pd.DataFrame(index=outliers[col[0]].unique(),columns=dt_range)\n",
    "    df = df.fillna(0).astype('float')\n",
    "    for idx in df.index:#stations/ids\n",
    "        vals = outliers[outliers[col[0]]==idx][[col[1]]].values\n",
    "        for val in vals:\n",
    "            if val in dt_range.values:\n",
    "                df.loc[idx][val] = outliers.loc[(outliers[col[0]]==idx)&(outliers[col[1]]==val[0])]['norm_resid']\n",
    "    if 'Green' in title:\n",
    "        figsize=(70, 8)\n",
    "    else:\n",
    "        figsize=(70, 16)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # my_colors=['whitesmoke','orangered']\n",
    "    \n",
    "    ax = sns.heatmap(df, cmap='bwr', center=0, xticklabels = df.columns.strftime('%Y-%m-%d,%H'),\n",
    "                     cbar_kws={\"shrink\":0.5},zorder=1)#,square=True)\n",
    "    # colorbar = ax.collections[0].colorbar\n",
    "    # colorbar.set_ticks([0.25,0.75])\n",
    "    # colorbar.set_ticklabels(['regular','irregular'])\n",
    "    # colorbar.ax.set_aspect(30)\n",
    "    for i in range(df.shape[0]+1):\n",
    "        ax.axhline(i, color='white', lw=1.5,zorder=2)\n",
    "    y1 = 0\n",
    "    y2 = len(df)\n",
    "\n",
    "    # ida_window = pd.to_datetime(['2021-08-26 00','2021-09-04 00'])\n",
    "    # ida_nyc_window = pd.to_datetime(['2021-09-01 00','2021-09-02 00'])\n",
    "    xlabels = ax.get_xticklabels()\n",
    "    print(xlabels[0].get_text())\n",
    "    print(xlabels[0])\n",
    "\n",
    "\n",
    "    xs = [ x.get_position()[0] for x in xlabels if str(x.get_text()) in [\"2021-09-01,00\",\"2021-09-03,00\"]]\n",
    "    x1 = xs[0]-0.5\n",
    "    x2 = xs[1]+0.5\n",
    "    print(xs)\n",
    "    # ax.fill_between([x1,x2],ida_window[0],ida_window[1], color='lightskyblue', alpha=0.4)\n",
    "    ax.fill_between([x1,x2],y1,y2,alpha=0.5, color='none',edgecolor='blue', zorder=3, label='Ida',linewidth=2.5)\n",
    "    \n",
    "    xs2 = [ x.get_position()[0] for x in xlabels if str(x.get_text()) in [\"2021-08-21,00\",\"2021-08-24,00\"]]\n",
    "    x12 = xs2[0]-0.5\n",
    "    x22 = xs2[1]+0.5\n",
    "    print(xs2)\n",
    "    ax.fill_between([x12,x22],y1,y2,alpha=0.8, color='none',edgecolor='gold', zorder=3,label='Henri',linewidth=2.5)\n",
    "    \n",
    "    xs3 = [ x.get_position()[0] for x in xlabels if str(x.get_text()) in [\"2021-07-08,00\",\"2021-07-10,00\"]]\n",
    "    x13 = xs3[0]-0.5\n",
    "    x23 = xs3[1]+0.5\n",
    "    print(xs3)\n",
    "    ax.fill_between([x13,x23],y1,y2, alpha=0.5, color='none',edgecolor='green', zorder=3, label='Elsa',linewidth=2.5)\n",
    "    \n",
    "    xs4 = [ x.get_position()[0] for x in xlabels if str(x.get_text()) in [\"2021-10-25,00\",\"2021-10-27,00\"]]\n",
    "    x14 = xs4[0]-0.5\n",
    "    x24 = xs4[1]+0.5\n",
    "    print(xs4)\n",
    "    ax.fill_between([x14,x24],y1,y2, alpha=0.5, color='none',edgecolor='deeppink', zorder=3,label=\"Nor'eastern\",linewidth=2.5)\n",
    "    \n",
    "    '''\n",
    "    xticks = ax.get_xticks()\n",
    "    for i, tick in enumerate(xticks):\n",
    "        if i % 2 == 0:\n",
    "            ax.xaxis.get_major_ticks()[i].set_visible(True)\n",
    "        else:\n",
    "            ax.xaxis.get_major_ticks()[i].set_visible(False)\n",
    "    '''\n",
    "    for i, label in enumerate(xlabels):\n",
    "        if i % 2 == 0:\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "    if \"Line's\" in title:\n",
    "        ax.tick_params(axis='x', labelsize=7)    \n",
    "    # ax.set_title(title)\n",
    "    ax.legend(ncol=4,loc='upper right',fontsize=30)\n",
    "    # 调整间距\n",
    "    fig = plt.gcf()\n",
    "    cax = fig.axes[-1]\n",
    "    plt.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.9, wspace=0.2, hspace=0.2)\n",
    "    cax.set_position([.796, .2, .03, .6]) # 调整colorbar的位置\n",
    "    plt.savefig(idir+'result/'+title.replace(':','_').replace('/',' ')+'.png',format='png',bbox_inches='tight',dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "# @jit(target_backend='cuda')    \n",
    "def find_outliers(idir,df,title):\n",
    "    if \"Pickups\" in title:\n",
    "        col = [\"PULocationID\",'pickup_datetime']\n",
    "    elif \"Dropoffs\" in title:\n",
    "        col = [\"DOLocationID\",'dropoff_datetime']\n",
    "    gps = df.groupby([col[0]])\n",
    "    # names = df[col[0]].unique()\n",
    "    outs = pd.DataFrame()\n",
    "    stas = pd.DataFrame()\n",
    "    \n",
    "    # df.hist(column=col[0])\n",
    "    # plt.show()\n",
    "    # return\n",
    "\n",
    "    for nm,df2 in gps:\n",
    "        # if len(df2)<200:\n",
    "        #     continue\n",
    "        nm = 'Z'+ str(nm)\n",
    "        df2['index'] = df2.index\n",
    "        sta_df = pd.DataFrame()\n",
    "        sta_df['cnt'] = df2.groupby([col[1]]).count()['index']\n",
    "        key='cnt'\n",
    "        if 'Green' in title:\n",
    "            if (sta_df['cnt'].mean()<6):\n",
    "                continue\n",
    "        elif 'Yellow' in title:\n",
    "            if (sta_df['cnt'].mean()<12):\n",
    "                continue\n",
    "        elif (sta_df['cnt'].mean()<12):\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        out = pd.DataFrame()\n",
    "        tmp,forecast =  Seasonal_Outliers.seasonal_de_hour(sta_df,key,plot=False)\n",
    "        if len(tmp)>0:\n",
    "            out[col[1]] = tmp\n",
    "            out[col[0]] = nm\n",
    "            outs = pd.concat([outs,out[col]],ignore_index=True)\n",
    "            forecast[col] = nm\n",
    "            stas = pd.concat([stas,forecast],ignore_index=True)\n",
    "\n",
    "    sst = stas[['ds','norm_resid',col[0]]]\n",
    "    print(sst,outs)\n",
    "    sst['ds'] = pd.to_datetime(sst['ds'], errors='coerce')\n",
    "    sst[col[1]] = sst['ds']\n",
    "    outs = pd.merge(outs,sst,on=col)\n",
    "    print(outs)\n",
    "    # for i in range(7):\n",
    "    #     # max_value = outs['norm_resid'].max()\n",
    "    #     outs.loc[outs['norm_resid'].idxmax(),'norm_resid'] = np.sqrt(outs.loc[outs['norm_resid'].idxmax(),'norm_resid'])#4 #处理异常大值\n",
    "    #     stas.loc[stas['norm_resid'].idxmax(),'norm_resid'] = np.sqrt(stas.loc[stas['norm_resid'].idxmax(),'norm_resid'])#4 #处理异常大值\n",
    "    #     outs.loc[outs['norm_resid'].idxmin(),'norm_resid'] = np.sqrt(outs.loc[outs['norm_resid'].idxmin(),'norm_resid'])#4 #处理异常大值\n",
    "    #     stas.loc[stas['norm_resid'].idxmin(),'norm_resid'] = np.sqrt(stas.loc[stas['norm_resid'].idxmin(),'norm_resid'])#4 #处理异常大值\n",
    "\n",
    "\n",
    "    vis(idir,outs,col, title)\n",
    "    stas.to_csv(idir+'result/'+title.replace(':','_').replace('/',' ')+'.csv',index=False)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def run(idir,files,_title):\n",
    "        \n",
    "    keys_dict = {\n",
    "        \"Zone's pickups\":[''],\n",
    "        \"Zone's dropoffs\":[''],\n",
    "                 \n",
    "                }\n",
    "    # df,dt_non_work = combine_df(idir,files)\n",
    "\n",
    "\n",
    "    for k,v in keys_dict.items():\n",
    "        if \"pickups\" in k:\n",
    "            title = _title + \"Zone's Pickups\"\n",
    "        if \"dropoffs\" in k:\n",
    "            title = _title + \"Zone's Dropoffs\"\n",
    "        find_outliers(idir,df,title)\n",
    "        \n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# if __name__=='__main__':\n",
    "    \n",
    "#     input_dir = \"\"\n",
    "#     items = [i for i in os.listdir(input_dir) if os.path.splitext(i)[1] == '.parquet']\n",
    "#     G_fi = [i for i in items if 'green' in i]\n",
    "#     Y_fi = [i for i in items if 'yellow' in i]\n",
    "#     _G_title = 'Hourly Stationarity of Green Taxi of '\n",
    "#     _Y_title = 'Hourly Stationarity of Yellow Taxi of '\n",
    "    \n",
    "#     df_G,dt_non_work = combine_df(input_dir,G_fi)\n",
    "#     df_Y,dt_non_work = combine_df(input_dir,Y_fi)\n",
    "    \n",
    "#     df = pd.concat([df_Y,df_G],ignore_index=True)\n",
    "#     _title = 'Hourly Stationarity of Taxi '\n",
    "#     # df.to_parquet('taxi_202107-10.parquet.gzip',index=False,compression='gzip')\n",
    "#     run(input_dir, df, _title)\n",
    "    \n",
    "#     # run(input_dir, G_fi, _G_title)\n",
    "#     # run(input_dir, Y_fi, _Y_title)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a470e928-1c30-4491-a651-3b773e866715",
   "metadata": {},
   "outputs": [],
   "source": [
    "    input_dir = \"\"\n",
    "    items = [i for i in os.listdir(input_dir) if os.path.splitext(i)[1] == '.parquet']\n",
    "    G_fi = [i for i in items if 'green' in i]\n",
    "    Y_fi = [i for i in items if 'yellow' in i]\n",
    "    _G_title = 'Hourly Stationarity of Green Taxi of '\n",
    "    _Y_title = 'Hourly Stationarity of Yellow Taxi of '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a68721-203b-4a24-ad25-f8f4e9fe1bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_G,dt_non_work = combine_df(input_dir,G_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9628cd8-5ce4-445d-a5e9-8911ab0ce71e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_Y,dt_non_work = combine_df(input_dir,Y_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26592fde-d6dd-454a-a51a-172b08fd2e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_Y,df_G],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec73495-93f4-4867-94ad-ba071d6cd500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport Seasonal_Outliers\n",
    "import importlib\n",
    "importlib.reload(Seasonal_Outliers)\n",
    "_title = 'Hourly Stationarity of Taxi '\n",
    "run(input_dir, df, _title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb98d0-721b-41a0-923b-28fea3683358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
