{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1ee69-fffe-41a0-9481-a704ddb3f868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport Seasonal_Outliers\n",
    "import importlib\n",
    "\n",
    "importlib.reload(Seasonal_Outliers)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from numba import jit,cuda\n",
    "import Ipynb_importer\n",
    "\n",
    "from prophet import Prophet\n",
    "import logging\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "import gc\n",
    " \n",
    "def read(file):\n",
    "    print(file)\n",
    "    df = pd.read_parquet(file)\n",
    "    print(df.head(2))\n",
    "    car_type=''\n",
    "    if 'fhv_' in file:\n",
    "        car_type='fhv'\n",
    "        df.rename(columns={'dropOff_datetime':'dropoff_datetime',\n",
    "                          'PUlocationID':'PULocationID',\n",
    "                          'DOlocationID':'DOLocationID'},inplace=True)\n",
    "        \n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')\n",
    "    df['pickup_date'] = df['pickup_datetime'].dt.date\n",
    "    df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'], errors='coerce')\n",
    "    df['dropoff_date'] = df['dropoff_datetime'].dt.date\n",
    "    df['Day of week'] = df['pickup_datetime'].dt.dayofweek\n",
    "    dt_wkends = df[df['Day of week']>4]['pickup_date'].unique()\n",
    "    \n",
    "    if car_type=='fhv':\n",
    "        return df,dt_wkends.tolist()\n",
    "    df.drop(['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num','shared_request_flag','airport_fee',\n",
    "             'shared_match_flag', 'access_a_ride_flag', 'wav_request_flag', 'wav_match_flag','bcf','congestion_surcharge'], axis=1,inplace=True)\n",
    "    # print(df.head(2))\n",
    "    \n",
    "    df['trip_time'] = pd.to_timedelta(df['trip_time'],unit='S')/pd.Timedelta(1,'h')\n",
    "    df['request_datetime'] = pd.to_datetime(df['request_datetime'], errors='coerce')\n",
    "    df['on_scene_datetime'] = pd.to_datetime(df['on_scene_datetime'], errors='coerce')\n",
    "    \n",
    "    \n",
    "\n",
    "    return df,dt_wkends.tolist()\n",
    "\n",
    "\n",
    "def combine_df(idir,files):\n",
    "    df = pd.DataFrame()\n",
    "    dt_non_work = []#non-working day\n",
    "    for fi in files:\n",
    "        dfi,dt_wkends = read(idir+fi)\n",
    "        df = df.append(dfi,ignore_index=True)\n",
    "        dt_non_work+=dt_wkends\n",
    "        del dfi\n",
    "        gc.collect()\n",
    "    holiday = pd.to_datetime(pd.Series(['2021-07-04','2021-07-05','2021-09-06','2021-09-16','2021-10-11'])).dt.date.unique()\n",
    "    dt_non_work = np.append(dt_non_work,holiday)#Labor Day\n",
    "\n",
    "    return df,dt_non_work\n",
    "\n",
    "\n",
    "def vis(idir,outliers,col,title):\n",
    "    \n",
    "    dt_range = pd.to_datetime(pd.date_range(start='07/01/2021', end='10/31/2021')).date\n",
    "    df = pd.DataFrame(columns=outliers[col[0]].unique(),index=dt_range)\n",
    "    df = df.fillna(0).astype('float')\n",
    "    for idx in df.index:#datetime\n",
    "        vals = outliers[outliers[col[1]]==idx][[col[0]]].values\n",
    "        for val in vals:\n",
    "            v = str(val[0])\n",
    "            df.loc[idx][val] = outliers.loc[(outliers[col[1]]==idx)&(outliers[col[0]].astype(str)==v)]['norm_resid'].values[0]\n",
    "\n",
    "    figsize=(24, 12)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # my_colors=['whitesmoke','orangered']\n",
    "    \n",
    "    ax = sns.heatmap(df,cmap='bwr',center=0,zorder=1, yticklabels = df.index,cbar_kws={\"pad\": 0.05})#square=True,\n",
    "    # colorbar = ax.collections[0].colorbar\n",
    "    # colorbar.set_ticks([0.25,0.75])\n",
    "    # colorbar.set_ticklabels(['regular','irregular'])\n",
    "    for i in range(df.shape[1]+1):\n",
    "        ax.axvline(i, color='white', lw=1.5, zorder=2)\n",
    "    x1 = 0\n",
    "    x2 = len(df.columns)\n",
    "\n",
    "    ylabels = ax.get_yticklabels()\n",
    "    ys = [ y.get_position()[1] for y in ylabels if str(y.get_text()) in [\"2021-09-01\",\"2021-09-02\"]]\n",
    "    y1 = ys[0]-0.5\n",
    "    y2 = ys[1]+0.5\n",
    "    print(ys)\n",
    "    # ax.fill_between([x1,x2],ida_window[0],ida_window[1], color='lightskyblue', alpha=0.4)\n",
    "    ax.fill_between([x1,x2],y1,y2, alpha=0.5, color='none',edgecolor='blue', zorder=3,label='Ida')\n",
    "    \n",
    "    ys2 = [ y.get_position()[1] for y in ylabels if str(y.get_text()) in [\"2021-08-21\",\"2021-08-23\"]]\n",
    "    y12 = ys2[0]-0.5\n",
    "    y22 = ys2[1]+0.5\n",
    "    print(ys2)\n",
    "    ax.fill_between([x1,x2],y12,y22, alpha=0.8, color='none',edgecolor='gold', zorder=3,label='Henri')\n",
    "    \n",
    "    ys3 = [ y.get_position()[1] for y in ylabels if str(y.get_text()) in [\"2021-07-08\",\"2021-07-09\"]]\n",
    "    y13 = ys3[0]-0.5\n",
    "    y23 = ys3[1]+0.5\n",
    "    print(ys3)\n",
    "    ax.fill_between([x1,x2],y13,y23, alpha=0.5, color='none',edgecolor='green', zorder=3,label='Elsa')\n",
    "    \n",
    "    ys4 = [ y.get_position()[1] for y in ylabels if str(y.get_text()) in ['2021-10-25','2021-10-26']]\n",
    "    y14 = ys4[0]-0.5\n",
    "    y24 = ys4[1]+0.5\n",
    "    print(ys4)\n",
    "    ax.fill_between([x1,x2],y14,y24, alpha=0.5, color='none',edgecolor='deeppink', zorder=3,label=\"Nor'eastern\")\n",
    "    \n",
    "   \n",
    "\n",
    "    for i, label in enumerate(ylabels):\n",
    "        if i % 2 == 0:\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "            \n",
    "    if \"Line's\" in title:\n",
    "        ax.tick_params(axis='y', labelsize=7)\n",
    "\n",
    "        \n",
    "    # ax.set_title(title)\n",
    "    ax.legend(ncol=4, loc='upper right',fontsize=18)\n",
    "    # \n",
    "    fig = plt.gcf()\n",
    "    cax = fig.axes[-1]\n",
    "    plt.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.9, wspace=0.2, hspace=0.2)\n",
    "    cax.set_position([.796, .2, .03, .6]) # \n",
    "    plt.savefig(idir+'result/'+title.replace(':','_').replace('/',' ')+'.png',format='png',bbox_inches='tight',dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "@jit(target_backend='cuda')    \n",
    "def find_outliers(idir,df,title):\n",
    "    if \"Pickups\" in title:\n",
    "        col = [\"PULocationID\",'pickup_date']\n",
    "    elif \"Dropoffs\" in title:\n",
    "        col = [\"DOLocationID\",'dropoff_date']\n",
    "    gps = df.groupby([col[0]])\n",
    "    # names = df[col[0]].unique()\n",
    "    outs = pd.DataFrame()\n",
    "    stas = pd.DataFrame()\n",
    "    for nm,df2 in gps:\n",
    "        # if len(df2)<200:\n",
    "        #     continue\n",
    "        nm = 'Z'+ str(nm)\n",
    "        df2['index'] = df2.index\n",
    "        sta_df = pd.DataFrame()\n",
    "        sta_df['cnt'] = df2.groupby([col[1]]).count()['index']\n",
    "        key='cnt'\n",
    "        if ' FHV' in title:\n",
    "            if (sta_df['cnt'].mean()<36):\n",
    "                continue\n",
    "        elif 'HVFHV' in title:\n",
    "            if (sta_df['cnt'].mean()<72):\n",
    "                continue\n",
    "        elif sta_df['cnt'].mean()<72:\n",
    "            continue\n",
    "        out = pd.DataFrame()\n",
    "        tmp,forecast = Seasonal_Outliers.seasonal_de_day(sta_df,key,plot=False)\n",
    "        if len(tmp)>0:\n",
    "            out[col[1]] = tmp\n",
    "            out[col[0]] = nm\n",
    "            outs = pd.concat([outs,out[col]],ignore_index=True)\n",
    "            forecast[col] = nm\n",
    "            stas = pd.concat([stas,forecast],ignore_index=True)\n",
    "\n",
    "    sst = stas[['ds','norm_resid',col[0]]]\n",
    "    print(sst,outs)\n",
    "    sst['ds'] = pd.to_datetime(sst['ds'], errors='coerce')\n",
    "    sst[col[1]] = sst['ds'].dt.date\n",
    "    outs = pd.merge(outs,sst,on=col)\n",
    "\n",
    "    vis(idir,outs,col, title)\n",
    "    stas.to_csv(idir+'result/'+title.replace(':','_').replace('/',' ')+'.csv',index=False)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def run(idir,files,_title):\n",
    "        \n",
    "    keys_dict = {\n",
    "        \"Zone's pickups\":[''],\n",
    "        \"Zone's dropoffs\":[''],\n",
    "                 \n",
    "                }\n",
    "    # df,dt_non_work = combine_df(idir,files)\n",
    "\n",
    "\n",
    "    for k,v in keys_dict.items():\n",
    "        if \"pickups\" in k:\n",
    "            title = _title + \"Zone's Pickups\"\n",
    "        if \"dropoffs\" in k:\n",
    "            title = _title + \"Zone's Dropoffs\"\n",
    "        find_outliers(idir,df,title)\n",
    "        \n",
    " \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974751a3-6e2b-4e18-bddf-b643b6456014",
   "metadata": {},
   "outputs": [],
   "source": [
    "    input_dir = \"\"\n",
    "    items = [i for i in os.listdir(input_dir) if os.path.splitext(i)[1] == '.parquet']\n",
    "    f_fi = [i for i in items if 'fhv_' in i]\n",
    "    hf_fi = [i for i in items if 'fhvhv' in i]\n",
    "    \n",
    "    _f_title = 'Daily Stationarity of FHV Taxi: '\n",
    "    _hf_title = 'Daily Stationarity of HVFHV Taxi: '\n",
    "    \n",
    "    df_f,dt_non_work = combine_df(input_dir,f_fi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfaee79-de31-4a9e-b345-d9741ee186b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_hf,dt_non_work = combine_df(input_dir,hf_fi)\n",
    "df = pd.concat([df_f,df_hf],ignore_index=True)\n",
    "# print(df)\n",
    "    \n",
    "del df_f\n",
    "del df_hf\n",
    "gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88857d81-3710-490f-b062-16b66cfa2935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport Seasonal_Outliers\n",
    "import importlib\n",
    "importlib.reload(Seasonal_Outliers)\n",
    "_title = 'Daily Stationarity of HVFHV Taxi '\n",
    "run(input_dir, df, _title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bcf92-8648-4aa1-a8b8-2d221147d230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
